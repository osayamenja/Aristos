{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:21.882038Z",
     "start_time": "2024-05-06T03:28:21.672744Z"
    }
   },
   "source": [
    "from main import grigora2, Worker, Group, expert_parallel_group_objective_function, all_reduce_function, gamma_function\n",
    "import numpy as np\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation of Lysi (renamed from Grigora)\n",
    "Let's perform realistic experiments using the sharding specification generated by Lysi.\n",
    "\n",
    "Specifically, we will use this [script](https://github.com/osayamenja/Megatron-DeepSpeed/blob/main/examples_deepspeed/MoE/ds_pretrain_gpt_350M_MoE128.sh) and train GPT-3 16x350M on four Perlmutter [GPU nodes](https://docs.nersc.gov/systems/perlmutter/architecture/#gpu-nodes) "
   ],
   "id": "1b98cda01d83063d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below, we define the number of workers and number of GPUs per node",
   "id": "f4b000c639d1d501"
  },
  {
   "cell_type": "code",
   "source": [
    "dim = 16\n",
    "intra_node_width = 4.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:21.887786Z",
     "start_time": "2024-05-06T03:28:21.884586Z"
    }
   },
   "id": "81336023e453319",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, we build the adjacency matrix. We manually obtained the alpha and beta values below via NCCL-tests mirco-benchmarks. \n",
    "We anticipate automating this network profiling procedure."
   ],
   "id": "e63a895718329b57"
  },
  {
   "cell_type": "code",
   "source": [
    "adjacency = np.zeros((dim, dim, 2))\n",
    "intra_node_cost = (0.009, 0.014)  # (ms, ms/MB)\n",
    "inter_node_cost = (0.03, 0.054)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:22.028452Z",
     "start_time": "2024-05-06T03:28:22.023367Z"
    }
   },
   "id": "98f56737dc97d3e7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that each GPU connects to a separate NIC in the Perlmutter; thus, there are only two types of links: intra-node NVLink and internode NIC connections.",
   "id": "3f356c44a3d0296f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:22.113984Z",
     "start_time": "2024-05-06T03:28:22.111162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for ii in range(adjacency.shape[0]):\n",
    "    for jj in range(adjacency.shape[0]):\n",
    "        if ii != jj and math.floor(jj / intra_node_width) == math.floor(ii / intra_node_width):\n",
    "            # intra-node\n",
    "            adjacency[ii, jj] = intra_node_cost\n",
    "        else:\n",
    "            # inter-node\n",
    "            adjacency[ii, jj] = inter_node_cost"
   ],
   "id": "f503dad0a433dcf0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below outlines the theoretical FLOPS of the tensor core in the A100 GPU, which comprises our testbed. We used the values from official [documentation](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf), *but* we obtained the realistic scaling factor from empirical measurements. \n",
    "\n",
    "Note this scale is much less than the 75% reported by [NVIDIA](https://forums.developer.nvidia.com/t/about-gpu-peak-performance/264462/5) but aligns with the [literature](https://ieeexplore.ieee.org/document/9415606), which details 40% utilization for $4096\\times4096$ matrices on the V100."
   ],
   "id": "d2506dfef2796c46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The expert matrix GEMMs for GPT-3 MoE are described below. Note that $\\bigotimes$ denotes matrix multiplication, $s$ sequence length, $h$ hidden size, and $b$ batch size.\n",
    "$$(s\\cdot b,\\; h)\\bigotimes (h, \\;4h) = (2048\\cdot 4, \\;1024) \\bigotimes (1024, \\;4096)$$   "
   ],
   "id": "e1e95d9b44e718d5"
  },
  {
   "cell_type": "code",
   "source": [
    "a100_theoretical_flop_per_ms = 312 * 1E9\n",
    "realistic_scaling_factor = 0.43\n",
    "real_flops = int(math.ceil(realistic_scaling_factor * a100_theoretical_flop_per_ms))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:24.775913Z",
     "start_time": "2024-05-06T03:28:24.773029Z"
    }
   },
   "id": "5c24c65bbca492b0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:25.040759Z",
     "start_time": "2024-05-06T03:28:25.038123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mem = 32\n",
    "w = []\n",
    "for ii in range(adjacency.shape[0]):\n",
    "    w.append(Worker(ii, real_flops, mem))"
   ],
   "id": "2b9ca12ab22947d1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We define the experts below.",
   "id": "2006a44b8fa2a3fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:25.322466Z",
     "start_time": "2024-05-06T03:28:25.320231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_exp = 64\n",
    "exp = []\n",
    "exp_flops = 16 * 4 * 2048 * (1024 ** 2)\n",
    "for ii in range(n_exp):\n",
    "    exp.append(exp_flops)"
   ],
   "id": "d92890f9dc082d7b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ensure to check this [file](grigora_manuscript.pdf) for more details.",
   "id": "e6d3c5600a4713f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:25.861579Z",
     "start_time": "2024-05-06T03:28:25.859149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p2p_buf_mb = 16\n",
    "p2p_fr = 4\n",
    "all_r_buf = 512\n",
    "\n",
    "gamma_arguments = {Group.NUM_LAYERS: 24,\n",
    "                   Group.GLOBAL_BATCH_SIZE: 256,\n",
    "                   Group.MINI_BATCH_SIZE: 4,\n",
    "                   Group.MOE_FREQUENCY: 2,\n",
    "                   Group.RECOMPUTATION_AMOUNT: 1}"
   ],
   "id": "994aa04c9acad76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T03:28:26.246271Z",
     "start_time": "2024-05-06T03:28:26.238950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shard_spec, inv = grigora2(a=adjacency,\n",
    "                               obj=expert_parallel_group_objective_function,\n",
    "                               all_reduce_func=all_reduce_function,\n",
    "                               gamma=gamma_function,\n",
    "                               p2p_buffer_size=p2p_buf_mb,\n",
    "                               p2p_freq=p2p_fr,\n",
    "                               all_reduce_buffer_size=all_r_buf,\n",
    "                               workers=w,\n",
    "                               expert_workload=exp,\n",
    "                               gamma_args=gamma_arguments)\n",
    "print(shard_spec.subsets())"
   ],
   "id": "3220bc550b1f04d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As shown above, Lysi produces a sharding specification where ranks of workers are grouped into communication-optimal groups.",
   "id": "ac236a239d7194af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
